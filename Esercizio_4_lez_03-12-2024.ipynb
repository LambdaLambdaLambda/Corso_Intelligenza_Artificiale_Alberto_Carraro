{"cells":[{"cell_type":"code","source":["!pip install torchviz"],"metadata":{"id":"du7OR8caxXLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"67uy3GPRu5yl","executionInfo":{"status":"ok","timestamp":1733149942548,"user_tz":-60,"elapsed":322,"user":{"displayName":"Alberto Carraro","userId":"11360352573163092996"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n","from scipy.stats import f\n","\n","import statsmodels.api as sm\n","import seaborn as sns\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchviz import make_dot\n","\n","import matplotlib.pyplot as plt\n","import os\n","\n","from IPython.display import Image"]},{"cell_type":"markdown","metadata":{"id":"HUpXda2du5ym"},"source":["**FUNZIONI PER VALUTARE LE PREDIZIONI SUL TEST SET**"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"CKYRz2OCu5yn","executionInfo":{"status":"ok","timestamp":1733150582716,"user_tz":-60,"elapsed":253,"user":{"displayName":"Alberto Carraro","userId":"11360352573163092996"}}},"outputs":[],"source":["def evaluate_predictions(X_test, y_test, y_pred):\n","    # R-squared (R²)\n","    r2 = r2_score(y_test, y_pred)\n","\n","    # Mean Absolute Error (MAE)\n","    mae = mean_absolute_error(y_test, y_pred)\n","\n","    # Mean Squared Error (MSE)\n","    mse = mean_squared_error(y_test, y_pred)\n","\n","    # Root Mean Squared Error (RMSE)\n","    rmse = np.sqrt(mse)\n","\n","    # Mean Absolute Percentage Error (MAPE)\n","    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n","\n","    # Residual Standard Error (RSE)\n","    # Residuals are the differences between the true values and the predictions\n","    residuals = y_test - y_pred\n","    # For simple linear regression, degrees of freedom = n - 2\n","    rse = np.sqrt(np.sum(residuals**2) / (len(y_test) - 2))\n","\n","    # Output all the results\n","    print(f\"R-squared (R²): {r2:.4f}\")\n","    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n","    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n","    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n","    print(f\"Mean Absolute Percentage Error (MAPE): {mape:.4f}%\")\n","    print(f\"Residual Standard Error (RSE): {rse:.4f}\")\n","    # Create the scatter plot\n","    plt.scatter(X_test, y_test, color='blue', marker='o',\n","                label='ground truth BHB values')\n","    plt.scatter(X_test, y_pred, color='red', marker='+',\n","                label='predicted BHB values')\n","    plt.axhline(y=1.2, color='green', linestyle='--',\n","                linewidth=2, label='Threshold per diagnosi')\n","    # Set labels and title\n","    plt.xlabel('Glu (mmol/L)')\n","    plt.ylabel('BHB (mmol/L)')\n","    plt.title('Scatter plot: ground truth and predictions on test set')\n","\n","    # Add a legend\n","    plt.legend()\n","\n","    # Display the plot\n","    plt.show()\n","\n","    # Create a histogram\n","    plt.figure(figsize=(8, 6))  # Adjust figure size if needed\n","    # kde=True adds a kernel density estimate\n","    sns.histplot(residuals, kde=True, bins=30)\n","    plt.title('Distribuzione dei residui')\n","    plt.xlabel('Residuai')\n","    plt.ylabel('Frequenza')\n","    plt.show()\n","\n","    # Create a Q-Q plot (optional)\n","    sm.qqplot(residuals, line='45', fit=True)\n","    plt.title('Q-Q Plot dei residui')\n","    plt.show()\n","\n","\n","# Function to compute TP, TN, FP, FN\n","def compute_confusion_matrix(boolean_predictions, boolean_ground_truth):\n","    TP = np.sum((boolean_predictions == True) & (\n","        boolean_ground_truth == True))   # Both True\n","    TN = np.sum((boolean_predictions == False) & (\n","        boolean_ground_truth == False))  # Both False\n","    # Predicted True, but False in ground truth\n","    FP = np.sum((boolean_predictions == True) &\n","                (boolean_ground_truth == False))\n","    # Predicted False, but True in ground truth\n","    FN = np.sum((boolean_predictions == False) &\n","                (boolean_ground_truth == True))\n","    return TP, TN, FP, FN\n","\n","\n","def compute_classification_metrics(TP, TN, FP, FN):\n","  \"\"\"\n","  Computes accuracy, recall, and F1 score.\n","\n","  Args:\n","    TP: True positives.\n","    TN: True negatives.\n","    FP: False positives.\n","    FN: False negatives.\n","\n","  Returns:\n","    A tuple containing accuracy, recall, and F1 score.\n","  \"\"\"\n","  accuracy = None\n","  recall = None\n","  precision = None\n","  f1_score = None\n","  if (TP + TN + FP + FN) > 0:\n","      accuracy = (TP + TN) / (TP + TN + FP + FN)\n","  if (TP + FN) > 0:\n","      recall = TP / (TP + FN)\n","  if (TP + FP) > 0:\n","      precision = TP / (TP + FP)\n","  if precision is not None and recall is not None and (precision + recall) > 0:\n","      f1_score = 2 * (precision * recall) / (precision + recall)\n","\n","  return accuracy, recall, precision, f1_score"]},{"cell_type":"markdown","metadata":{"id":"eVTs-ecTu5yn"},"source":["Cliccare sull'icona della cartella qui a sinistra. Quando si apre lo spazio di lavoro dei file, trascinare il file 'Holstein_diary_cows.csv' dal proprio computer all'area qui a sinistra. In seguito eseguire la prossima cella."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"--xDxAo8u5yn","executionInfo":{"status":"ok","timestamp":1733149353624,"user_tz":-60,"elapsed":406,"user":{"displayName":"Alberto Carraro","userId":"11360352573163092996"}}},"outputs":[],"source":["cvs_source= 'Holstein_diary_cows.csv'\n","df = pd.read_csv(cvs_source)"]},{"cell_type":"markdown","metadata":{"id":"m8ETbfpau5yn"},"source":["**Eseguire la prossima cella per visualizzare il dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aFpDl55Lu5yn"},"outputs":[],"source":["# Create the scatter plot\n","plt.scatter(df['Glu'], df['BHB'])\n","\n","# Set labels and title\n","plt.xlabel('Glu (mmol/L)')\n","plt.ylabel('BHB (mmol/L)')\n","plt.title('Scatter plot: Glu vs BHB')\n","\n","# Add a legend\n","plt.legend()\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"aSzrg-Fbu5yn"},"source":["**DIVIDI IL DATASET IN 80% TRAIN E 20% TEST**"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"z2qLVcl5u5yo","executionInfo":{"status":"ok","timestamp":1733149362940,"user_tz":-60,"elapsed":277,"user":{"displayName":"Alberto Carraro","userId":"11360352573163092996"}}},"outputs":[],"source":["X = df[['Glu']]  # Features (independent variable)\n","y = df['BHB']    # Target (dependent variable)\n","\n","# Split data into training and testing sets (80% train, 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"iDyy8V4Fu5yo"},"source":["**CREA E ALLENA UNA FULLY CONNECTED NEURAL NETWORK**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YonizB4Zu5yo"},"outputs":[],"source":["# Define the neural network model\n","class SimpleNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleNN, self).__init__()\n","        self.hidden = nn.Linear(1, 10)  # Input layer to hidden layer (10 neurons)\n","        self.activation = nn.ReLU()    # Activation function\n","        self.output = nn.Linear(10, 1) # Hidden layer to output layer\n","\n","    def forward(self, x):\n","        x = self.hidden(x)\n","        x = self.activation(x)\n","        x = self.output(x)\n","        return x\n","\n","# Initialize the model, loss function, and optimizer\n","model = SimpleNN()\n","criterion = nn.MSELoss()  # Mean Squared Error Loss\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","X_train_tensor = torch.from_numpy(X_train.values).float()\n","y_train_tensor = torch.from_numpy(\n","    y_train.values).float().view(-1, 1)  # Reshape to (n_samples, 1)\n","\n","\n","# Training loop\n","epochs = 70\n","for epoch in range(epochs):\n","    # Forward pass\n","    y_pred = model(X_train_tensor)\n","    loss = criterion(y_pred, y_train_tensor)\n","\n","    # Backward pass\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Print loss every 10 epochs\n","    if (epoch + 1) % 10 == 0:\n","        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"XdZcmWQcu5yo"},"source":["**VISUALIZZA LA RETE NEURALE**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XQO1PEDu5yo"},"outputs":[],"source":["# Create a dummy input tensor with the correct input size\n","dummy_input = torch.randn(1, 1)  # Batch size of 1, input size of 1\n","\n","# Perform a forward pass to generate the computation graph\n","output = model(dummy_input)\n","\n","# Use torchviz to visualize the computation graph\n","dot = make_dot(output, params=dict(model.named_parameters()))\n","dot.render(\"fully_connected_model\", format=\"png\", view=True)"]},{"cell_type":"markdown","metadata":{"id":"Lyf3sKCKu5yo"},"source":["**APPLICA IL MODELLO SUL TEST SET E VALUTA LE SUE PREDIZIONI**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0X_Z9xxNu5yo"},"outputs":[],"source":["if not isinstance(X_test, np.ndarray):\n","    X_test = X_test.values\n","\n","if not isinstance(y_test, np.ndarray):\n","    y_test = y_test.values\n","\n","# Convert X_test to a PyTorch tensor\n","X_test_tensor = torch.from_numpy(X_test).float()\n","y_test_tensor = torch.from_numpy(y_test).float().view(-1, 1)\n","\n","# Evaluate the model on the test set\n","model.eval()  # Set the model to evaluation mode\n","with torch.no_grad():\n","    y_pred = model(X_test_tensor).numpy()\n","\n","y_pred = y_pred.flatten()\n","\n","if not isinstance(y_test, np.ndarray):\n","  y_test = y_test.values\n","\n","threshold = 1.2  # The threshold value\n","\n","# Create boolean arrays\n","bool_y_test = y_test >= threshold\n","bool_y_pred = y_pred >= threshold\n","\n","# Compute metrics for each prediction array\n","TP, TN, FP, FN = compute_confusion_matrix(bool_y_pred, bool_y_test)\n","accuracy, recall, precision, f1_score = compute_classification_metrics(\n","    TP, TN, FP, FN)\n","\n","print(\"Matrice di confusione:\")\n","print(f\"TP: {TP}\")\n","print(f\"TN: {TN}\")\n","print(f\"FP: {FP}\")\n","print(f\"FN: {FN}\")\n","print(\"Metriche del classificatore:\")\n","print(f\"Accuratezza: {accuracy}\")\n","print(f\"Richiamo: {recall}\")\n","print(f\"Precisione: {precision}\")\n","print(f\"F1: {f1_score}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}