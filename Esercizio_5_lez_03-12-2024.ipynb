{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"88FjEkljpQom","executionInfo":{"status":"ok","timestamp":1733148794744,"user_tz":-60,"elapsed":427,"user":{"displayName":"Alberto Carraro","userId":"11360352573163092996"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n","from sklearn.cross_decomposition import PLSRegression\n","from scipy.stats import f\n","from scipy import stats\n","from scipy.stats import shapiro\n","\n","import statsmodels.api as sm\n","import seaborn as sns\n","from statsmodels.stats.diagnostic import het_breuschpagan\n","import statsmodels.api as sm\n","\n","import matplotlib.pyplot as plt\n","import os\n","import json"]},{"cell_type":"markdown","metadata":{"id":"pAbTVLHisUIu"},"source":["**FUNZIONI PER VALUTARE LE PREDIZIONI SUL TEST SET**"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"TACnVtvIsTFq","executionInfo":{"status":"ok","timestamp":1733148797193,"user_tz":-60,"elapsed":278,"user":{"displayName":"Alberto Carraro","userId":"11360352573163092996"}}},"outputs":[],"source":["def evaluate_predictions(X_test, y_test, y_pred):\n","    # R-squared (R²)\n","    r2 = r2_score(y_test, y_pred)\n","\n","    # Mean Absolute Error (MAE)\n","    mae = mean_absolute_error(y_test, y_pred)\n","\n","    # Mean Squared Error (MSE)\n","    mse = mean_squared_error(y_test, y_pred)\n","\n","    # Root Mean Squared Error (RMSE)\n","    rmse = np.sqrt(mse)\n","\n","    # Mean Absolute Percentage Error (MAPE)\n","    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n","\n","    # Residual Standard Error (RSE)\n","    # Residuals are the differences between the true values and the predictions\n","    residuals = y_test - y_pred\n","    rse = np.sqrt(np.sum(residuals**2) / (len(y_test) - 2))  # For simple linear regression, degrees of freedom = n - 2\n","\n","    return r2, mae, mse, rmse, mape, rse\n","\n","\n","def print_evaluation_metrics(r2, mae, mse, rmse, mape, rse):\n","    print(f\"R-squared (R²): {r2:.4f}\")\n","    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n","    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n","    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n","    print(f\"Mean Absolute Percentage Error (MAPE): {mape:.4f}%\")\n","    print(f\"Residual Standard Error (RSE): {rse:.4f}\")\n","\n","\n","# Function to compute TP, TN, FP, FN\n","def compute_confusion_matrix(boolean_predictions, boolean_ground_truth):\n","    TP = np.sum((boolean_predictions == True) & (boolean_ground_truth == True))   # Both True\n","    TN = np.sum((boolean_predictions == False) & (boolean_ground_truth == False)) # Both False\n","    FP = np.sum((boolean_predictions == True) & (boolean_ground_truth == False))  # Predicted True, but False in ground truth\n","    FN = np.sum((boolean_predictions == False) & (boolean_ground_truth == True))  # Predicted False, but True in ground truth\n","    return TP, TN, FP, FN\n","\n","\n","def compute_classification_metrics(TP, TN, FP, FN):\n","    \"\"\"\n","    Computes accuracy, recall, and F1 score.\n","\n","    Args:\n","      TP: True positives.\n","      TN: True negatives.\n","      FP: False positives.\n","      FN: False negatives.\n","\n","    Returns:\n","      A tuple containing accuracy, recall, and F1 score.\n","    \"\"\"\n","    accuracy = (TP + TN) / (TP + TN + FP + FN)\n","    recall = TP / (TP + FN)\n","    precision = TP / (TP + FP)\n","    f1_score = 2 * (precision * recall) / (precision + recall)\n","\n","    return accuracy, recall, precision, f1_score"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"BkwHYTIM7lvt","executionInfo":{"status":"ok","timestamp":1733148801913,"user_tz":-60,"elapsed":320,"user":{"displayName":"Alberto Carraro","userId":"11360352573163092996"}}},"outputs":[],"source":["cvs_source= 'Holstein_diary_cows.csv'\n","df = pd.read_csv(cvs_source)"]},{"cell_type":"markdown","metadata":{"id":"aY-0I3Bk8aiH"},"source":["**Eseguire la prossima cella per visualizzare il dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4S5fD9AeqcMi"},"outputs":[],"source":["# Create the scatter plot\n","plt.scatter(df['Glu'], df['BHB'])\n","\n","# Set labels and title\n","plt.xlabel('Glu (mmol/L)')\n","plt.ylabel('BHB (mmol/L)')\n","plt.title('Scatter plot: Glu vs BHB')\n","\n","# Add a legend\n","plt.legend()\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"05sLXt4K8hTU"},"source":["**DIVIDI IL DATASET IN 10 DIVERSI SPLIT CIASCUNO 80% TRAIN E 20% TEST**"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"tXmhvst18zn9","executionInfo":{"status":"ok","timestamp":1733148808890,"user_tz":-60,"elapsed":2,"user":{"displayName":"Alberto Carraro","userId":"11360352573163092996"}}},"outputs":[],"source":["X = df[['Glu']]  # Features (independent variable)\n","y = df['BHB']    # Target (dependent variable)\n","\n","df['Glu_bin'] = 0\n","\n","min_val = df['Glu'].min()\n","max_val = df['Glu'].max()\n","delta = abs(max_val-min_val)\n","\n","# Iterate over rows and assign bin values based on conditions\n","for idx, row in df.iterrows():\n","    if min_val <= row['Glu'] < min_val+(1.0/6.0)*delta:\n","        df.loc[idx, 'Glu_bin'] = 1\n","    elif min_val+(1.0/6.0)*delta <= row['Glu'] < min_val+(2.0/6.0)*delta:\n","        df.loc[idx, 'Glu_bin'] = 2\n","    elif min_val+(2.0/6.0)*delta <= row['Glu'] < min_val+(3.0/6.0)*delta:\n","        df.loc[idx, 'Glu_bin'] = 3\n","    elif min_val+(3.0/6.0)*delta <= row['Glu'] < min_val+(4.0/6.0)*delta:\n","        df.loc[idx, 'Glu_bin'] = 4\n","    elif min_val+(4.0/6.0)*delta <= row['Glu'] < min_val+(5.0/6.0)*delta:\n","        df.loc[idx, 'Glu_bin'] = 5\n","    elif min_val+(5.0/6.0)*delta <= row['Glu'] <= max_val:\n","        df.loc[idx, 'Glu_bin'] = 6\n","\n","stratifier = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n","\n","# Stratify based on 'energy_bin' column\n","strat_column = df['Glu_bin']\n","\n","splits = []\n","for train_index, test_index in stratifier.split(X, strat_column):\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    splits.append((X_train, X_test, y_train, y_test))"]},{"cell_type":"markdown","metadata":{"id":"IKnHfW6YFbMI"},"source":["**CREA, ALLENA ED APPLICA UN MODELLO DI RANDOM FOREST REGRESSION SU CIASCUNO SPLIT**"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"5KYnuYTMF4MQ","executionInfo":{"status":"ok","timestamp":1733148817433,"user_tz":-60,"elapsed":1761,"user":{"displayName":"Alberto Carraro","userId":"11360352573163092996"}}},"outputs":[],"source":["predictions = []\n","for X_train, X_test, y_train, y_test in splits:\n","    y_test = y_test.to_numpy().reshape(-1)\n","    model = RandomForestRegressor(n_estimators=100, random_state=42)  # You can adjust hyperparameters\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    predictions.append((X_test, y_test, y_pred))\n","    del model"]},{"cell_type":"markdown","metadata":{"id":"uFyWC0bsExlE"},"source":["**VALUTA LE PREDIZIONI MEDIE**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g90IUpydE31H"},"outputs":[],"source":["threshold = 1.2  # The threshold value\n","\n","rows = []\n","for X_test, y_test, y_pred in predictions:\n","\n","    if not isinstance(y_test, np.ndarray):\n","        y_test = y_test.values\n","\n","    r2, mae, mse, rmse, mape, rse = evaluate_predictions(X_test, y_test, y_pred)\n","\n","    # Create boolean arrays\n","    bool_y_test = y_test >= threshold\n","    bool_y_pred = y_pred >= threshold\n","\n","    # Compute metrics for each prediction array\n","    TP, TN, FP, FN = compute_confusion_matrix(bool_y_pred, bool_y_test)\n","    accuracy, recall, precision, f1_score = compute_classification_metrics(TP, TN, FP, FN)\n","\n","    row = {\n","        'R2': r2,\n","        'MAE': mae,\n","        'MSE': mse,\n","        'RMSE': rmse,\n","        'MAPE': mape,\n","        'RSE': rse,\n","        'TP': TP,\n","        'TN': TN,\n","        'FP': FP,\n","        'FN': FN,\n","        'Accuracy': accuracy,\n","        'Recall': recall,\n","        'Precision': precision,\n","        'F1': f1_score\n","    }\n","    rows.append(row)\n","\n","results_df = pd.DataFrame(rows)\n","results_df.index.name = 'Split'\n","# Compute descriptive statistics for each column\n","descriptive_stats = results_df.agg(['min', 'max', 'mean', 'std'])\n","\n","# Display the results\n","print(descriptive_stats)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}