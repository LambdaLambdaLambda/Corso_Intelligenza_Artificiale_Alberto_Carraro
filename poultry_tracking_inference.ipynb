{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wd3Se2XnRN0E"
   },
   "source": [
    "**IF THE SCRIPT IS RUN IN COLAB, WE NEED TO INSTALL TWO PACKAGES**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93fjNrTZRN0H",
    "outputId": "af42bf40-d2f6-4379-c6ab-b9f869d8c76b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting supervision\n",
      "  Downloading supervision-0.25.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.3.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.23.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.26.4)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from supervision) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.10/dist-packages (from supervision) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (6.0.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.13.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\n",
      "Downloading supervision-0.25.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: supervision\n",
      "Successfully installed supervision-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_oIP51myRN0I",
    "outputId": "699cf7cc-2947-43e8-d33d-6593ed4538d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.40-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.40-py3-none-any.whl (898 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.5/898.5 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ultralytics-thop, ultralytics\n",
      "Successfully installed ultralytics-8.3.40 ultralytics-thop-2.0.12\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMdlLEd5RN0J"
   },
   "source": [
    "**IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_ULq6OpRN0J"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from enum import Enum\n",
    "import time\n",
    "from typing import List, Generator, Dict, Any, Tuple, Union, Set\n",
    "from types import SimpleNamespace\n",
    "from dataclasses import dataclass\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "from IPython.display import display, Image\n",
    "from shapely.geometry import box\n",
    "from shapely.ops import unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RuQsiEHRN0J",
    "outputId": "f3e416c2-5372-4be1-d60d-f57736bdf776"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import humanize\n",
    "import psutil\n",
    "import GPUtil\n",
    "import supervision as sv\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.engine.results import Results\n",
    "from supervision.detection.core import Detections\n",
    "from supervision.tracker.byte_tracker.core import ByteTrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Jv_snt2rRN0J"
   },
   "outputs": [],
   "source": [
    "class Labels(Enum):\n",
    "    gallina_bianca = 0\n",
    "    gallina_rossa = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file name and URL\n",
    "file_name = \"ExternDisk0_ch4_20240207130000_20240207140000.mp4\"\n",
    "url = \"https://www.dropbox.com/scl/fi/rwz8irhljs0dm08yy2zku/ExternDisk0_ch4_20240207130000_20240207140000.mp4?rlkey=fi02g6j9hlet481hw9kk4inru&st=08kvj8ln&dl=0\"\n",
    "\n",
    "# Download the file using wget\n",
    "os.system(f\"wget -O {file_name} '{url}'\")\n",
    "\n",
    "print(f\"File '{file_name}' scaricato nella directory corrente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnvQyBMfRN0K"
   },
   "source": [
    "**FUNCTIONS FOR TRACKING AND COMPUTATION OF KINETIC INDICES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvM-GTw7RN0K"
   },
   "outputs": [],
   "source": [
    "def annotate_frame(\n",
    "    detections: Detections,\n",
    "    frame: np.ndarray) -> np.ndarray:\n",
    "\n",
    "    n = len(detections.xyxy)\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    if detections.class_id is not None and detections.tracker_id is not None and n > 0 and len(detections.class_id) == len(detections.tracker_id) == n:\n",
    "        labels = [\n",
    "            f\"{Labels(detections.class_id[i]).name}#{detections.tracker_id[i]}\"\n",
    "            for i in range(n)\n",
    "        ]\n",
    "    elif detections.class_id is not None and n > 0:\n",
    "        labels = [\n",
    "            f\"{Labels(detections.class_id[i]).name}\"\n",
    "            for i in range(n)\n",
    "        ]\n",
    "\n",
    "    box_annotator = sv.BoxAnnotator()\n",
    "    label_annotator = sv.LabelAnnotator(text_position=sv.Position.CENTER)\n",
    "\n",
    "    annotated_frame = box_annotator.annotate(\n",
    "        scene=frame,\n",
    "        detections=detections\n",
    "    )\n",
    "    annotated_frame = label_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=detections,\n",
    "        labels=labels\n",
    "    )\n",
    "\n",
    "    return annotated_frame\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "def main(\n",
    "        input_video_path: str,\n",
    "        start_second: int,\n",
    "        end_second: int,\n",
    "        output_video_path: str,\n",
    "        weight_file: str,\n",
    "        tracker_file: str,\n",
    "        device: torch.device,\n",
    "        class_of_interest: int\n",
    "    ) -> Generator[\n",
    "          Tuple[Dict[str, Any], List[Dict[str, Any]], List[Dict[str, Any]]],\n",
    "          None,\n",
    "          None\n",
    "        ]:\n",
    "\n",
    "    #################################################\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    frame_width = None\n",
    "    frame_height = None\n",
    "    fps = None\n",
    "    number_of_frames = 0\n",
    "    fourcc = None\n",
    "    output_video = None\n",
    "    print(f\"Video: {input_video_path}\")\n",
    "    #################################################\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: unable to open the video.\")\n",
    "        cap.release()\n",
    "    else:\n",
    "        # Get the resolution of frames\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        number_of_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        if output_video_path is not None:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            output_video = cv2.VideoWriter(\n",
    "                output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "        tracker = None\n",
    "        if FRAME_BUFFER_DIM > 1:\n",
    "            tracker = ByteTrack(track_activation_threshold=0.25,\n",
    "                                lost_track_buffer=30,\n",
    "                                minimum_matching_threshold=0.8,\n",
    "                                frame_rate=fps,\n",
    "                                minimum_consecutive_frames=1)\n",
    "            tracker.reset()\n",
    "    #################################################\n",
    "    current_batch_of_results = None\n",
    "    frame_buffer_list = []\n",
    "    frame_id_list = []\n",
    "    batch_id = 0\n",
    "    previous_avg = None\n",
    "    previous_result = None\n",
    "    previous_detections = None\n",
    "    extreme_values_occurrences = 0\n",
    "    first_frame_of_interest = 0\n",
    "    last_frame_of_interest = number_of_frames\n",
    "    if start_second is not None and start_second >= 0 and end_second is not None and end_second >= start_second:\n",
    "        first_frame_of_interest = int(start_second*fps)\n",
    "        last_frame_of_interest = int(min(end_second*fps, number_of_frames))\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, first_frame_of_interest)\n",
    "\n",
    "    #################################################\n",
    "    model = YOLO(weight_file)\n",
    "    model.to(device)\n",
    "    #################################################\n",
    "    for frame_id in tqdm(range(first_frame_of_interest, last_frame_of_interest)):\n",
    "        ####\n",
    "        if not cap.isOpened():\n",
    "            break\n",
    "\n",
    "        success, frame_hwc = cap.read()\n",
    "\n",
    "        if not success:\n",
    "            continue\n",
    "        ####\n",
    "        frame_buffer_list.append(frame_hwc)\n",
    "        frame_id_list.append(frame_id)\n",
    "        ####\n",
    "        if (frame_id-first_frame_of_interest) > 0 and FRAME_BUFFER_DIM > 1 and ((frame_id-first_frame_of_interest)%FRAME_BUFFER_DIM == 0 or frame_id >= last_frame_of_interest-1):\n",
    "            #print(f\"frame_id_list == {frame_id_list}\")\n",
    "            start = time.time()\n",
    "            current_batch_of_results = model.predict(  # parallel inference on the entire batch without tracking\n",
    "                frame_buffer_list,\n",
    "                verbose=False,\n",
    "                classes=[class_of_interest])\n",
    "            end = time.time()\n",
    "            batch_aggregate_measurements = {\n",
    "                'batch_id': int(batch_id),\n",
    "                'yolo_detection_time': float(end-start)\n",
    "            }\n",
    "\n",
    "            frame_aggregate_measurements_list, bbox_predictions_list, current_batch_of_detections = process_current_batch_detection_results(\n",
    "                batch_id,\n",
    "                frame_id_list,\n",
    "                previous_detections,\n",
    "                current_batch_of_results,\n",
    "                tracker,\n",
    "                device,\n",
    "                frame_width,\n",
    "                frame_height,\n",
    "                class_of_interest,\n",
    "                selective_calculation)\n",
    "            # frame_aggregate_measurements_list: List[Dict[str, Any]]\n",
    "            # bbox_predictions_list: List[Dict[str, Any]]\n",
    "            # current_batch_of_detections: List[Detections]\n",
    "\n",
    "            if current_batch_of_detections is not None and len(current_batch_of_detections) > 0:\n",
    "                previous_detections = current_batch_of_detections[-1]\n",
    "\n",
    "            batch_id += 1\n",
    "            ####\n",
    "            frame_buffer_list.clear()\n",
    "            frame_id_list.clear()\n",
    "            ##########################################################\n",
    "            \"\"\"\n",
    "            if output_video_path is not None:\n",
    "                for frame_hwc, detections in zip(frame_buffer_list, current_batch_of_detections):\n",
    "                    annotated_frame = annotate_frame(detections, frame_hwc.copy())\n",
    "                    output_video.write(annotated_frame)\n",
    "            \"\"\"\n",
    "            ##########################################################\n",
    "            yield batch_aggregate_measurements, frame_aggregate_measurements_list, bbox_predictions_list\n",
    "        ###\n",
    "        elif FRAME_BUFFER_DIM == 1:\n",
    "            start = time.time()\n",
    "            current_result = model.track(  # sequential inference with tracking\n",
    "                    source=frame_hwc,\n",
    "                    stream=False,\n",
    "                    persist=True,\n",
    "                    tracker=tracker_file,\n",
    "                    verbose=False,\n",
    "                    show=False,\n",
    "                    classes=[class_of_interest])\n",
    "            end = time.time()\n",
    "            frame_aggregate_measurements, bbox_predictions_list = process_current_frame_tracking_results(\n",
    "                frame_id,\n",
    "                previous_result,\n",
    "                current_result[0],\n",
    "                device,\n",
    "                frame_width,\n",
    "                frame_height,\n",
    "                class_of_interest)\n",
    "            frame_aggregate_measurements['yolo_tracking_time'] = (end-start)\n",
    "\n",
    "            # frame_aggregate_measurements: Dict[str, Any]\n",
    "            # bbox_predictions_list: List[Dict[str, Any]]\n",
    "            previous_result = current_result[0]\n",
    "\n",
    "            frame_aggregate_measurements_list = [frame_aggregate_measurements]\n",
    "\n",
    "            yield None, frame_aggregate_measurements_list, bbox_predictions_list\n",
    "        ###\n",
    "\n",
    "    # Release the video capture object and close the display window\n",
    "    cap.release()\n",
    "    if output_video_path is not None:\n",
    "        output_video.release()\n",
    "        del output_video\n",
    "        del fourcc\n",
    "    if tracker is not None:\n",
    "        del tracker\n",
    "    del model\n",
    "    # end of for loop\n",
    "    # end of main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PWql7PSRN0L"
   },
   "outputs": [],
   "source": [
    "best_weights = os.path.join(\n",
    "    'runs', 'detect', 'train_2_yolo11n', 'weights', 'best.pt')\n",
    "\n",
    "base_folder = os.path.join('raw_video_source')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4_ziE402ZHM"
   },
   "source": [
    "**FOR WHITE HENS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1j37xeHn2W5A"
   },
   "outputs": [],
   "source": [
    "input_video_name = 'ExternDisk0_ch4_20240207130000_20240207140000.mp4'\n",
    "cage = 'mod_1_galline_bianche'\n",
    "day = '07-02-2024'\n",
    "start_second = 52*60+46\n",
    "end_second = 52*60+56\n",
    "class_of_interest = Labels.gallina_bianca.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1osXsWZRN0M"
   },
   "source": [
    "**CALCULATION OF PREDICTED KINETIC INDICES FOR THE SELECTED VIDEO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwsR7sDA2f_r",
    "outputId": "5e73e9f8-533b-4e6f-8abd-6a047728bb42"
   },
   "outputs": [],
   "source": [
    "####\n",
    "input_video_path  = os.path.join(base_folder, 'raw_video_source', cage,\n",
    "                                 day, input_video_name)\n",
    "save_csv_to_drive = True\n",
    "tracker_file = 'bytetrack.yaml'\n",
    "#tracker_file = 'botsort.yaml'\n",
    "selective_calculation = False\n",
    "\n",
    "parameter_pairs = [(1, False)] + list(itertools.product([4, 8, 16, 32, 64, 128], [False, True]))\n",
    "####\n",
    "for FRAME_BUFFER_DIM, selective_calculation in parameter_pairs:\n",
    "\n",
    "    #output_video_path = os.path.join(base_folder, 'raw_video_source', cage,\n",
    "    #                                day, f'{Path(input_video_name).stem}_secs_{start_second}-to-{end_second}_FRAME_BUFFER_DIM-{FRAME_BUFFER_DIM}.mp4')\n",
    "    output_video_path = None\n",
    "    ####\n",
    "    #output_images_dir = os.path.join(base_folder, 'raw_video_source', cage,\n",
    "    #                               day, f\"{Path(input_video_name).stem}_secs_{start_second}-to-{end_second}_images_FRAME_BUFFER_DIM-{FRAME_BUFFER_DIM}\")\n",
    "    #if not os.path.exists(output_images_dir):\n",
    "    #    os.makedirs(output_images_dir)\n",
    "    output_images_dir = None\n",
    "    ####\n",
    "\n",
    "    perform_tracking = True\n",
    "\n",
    "    if perform_tracking:\n",
    "\n",
    "        device = torch.device(\"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            torch.cuda.empty_cache()\n",
    "            # setting device on GPU if available, else CPU\n",
    "            print('Using device:', device)\n",
    "            #Additional Info when using cuda\n",
    "            if device.type == 'cuda':\n",
    "                print(torch.cuda.get_device_name(0))\n",
    "                print('Memory Usage:')\n",
    "                print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "                print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "            mem_rep_record = mem_report()\n",
    "            json_str = json.dumps(mem_rep_record, indent=4)\n",
    "            print(json_str)\n",
    "\n",
    "        frame_aggregate_measurements_list_tot = []\n",
    "        bbox_predictions_list_tot = []\n",
    "        batch_aggregate_measurements_list = []\n",
    "        #counter = 0\n",
    "\n",
    "        for batch_aggregate_measurements, frame_aggregate_measurements_list, bbox_predictions_list in main(input_video_path=input_video_path,\n",
    "                                        start_second=start_second,\n",
    "                                        end_second=end_second,\n",
    "                                        output_video_path=output_video_path,\n",
    "                                        weight_file=best_weights,\n",
    "                                        tracker_file=tracker_file,\n",
    "                                        FRAME_BUFFER_DIM=FRAME_BUFFER_DIM,\n",
    "                                        device=device,\n",
    "                                        class_of_interest=class_of_interest,\n",
    "                                        selective_calculation=selective_calculation):\n",
    "\n",
    "            frame_aggregate_measurements_list_tot.extend(frame_aggregate_measurements_list)\n",
    "            bbox_predictions_list_tot.extend(bbox_predictions_list)\n",
    "            if batch_aggregate_measurements is not None:\n",
    "                batch_aggregate_measurements_list.append(batch_aggregate_measurements)\n",
    "        ### end for loop #################################################\n",
    "        output_labels_and_measurements_dir = os.path.join(base_folder, 'raw_video_source', 'mod_1_galline_bianche',\n",
    "                                     day, f\"{Path(input_video_name).stem}_secs_{start_second}-to-{end_second}_pred_({FRAME_BUFFER_DIM}-{selective_calculation})\")\n",
    "        if not os.path.exists(output_labels_and_measurements_dir):\n",
    "            os.makedirs(output_labels_and_measurements_dir)\n",
    "        ######### SAVE PREDICTED BOUNDING BOXES ##########################\n",
    "        bbox_predictions_df = pd.DataFrame(bbox_predictions_list_tot)\n",
    "        bbox_predictions_csv_file = os.path.join(output_labels_and_measurements_dir, \"labels.csv\")\n",
    "        # bounding box coordinates are normalized, just as the ground truth bounding boxes\n",
    "        if save_csv_to_drive:\n",
    "            bbox_predictions_df.to_csv(bbox_predictions_csv_file, index=False, header=False)\n",
    "            if not os.path.exists(bbox_predictions_csv_file):\n",
    "                print(f\"Saved file {bbox_predictions_csv_file}.\")\n",
    "            else:\n",
    "                print(f\"File {bbox_predictions_csv_file} overwritten.\")\n",
    "\n",
    "        del bbox_predictions_list_tot\n",
    "        del bbox_predictions_df\n",
    "        ######### SAVE PREDICTED MEASUREMENTS ############################\n",
    "        frame_aggregate_measurements_df = pd.DataFrame(frame_aggregate_measurements_list_tot)\n",
    "        if FRAME_BUFFER_DIM > 1 and selective_calculation:\n",
    "            # the field 'displacement' is NaN in half of the records if BUFF_DIM > 1\n",
    "            frame_aggregate_measurements_df['displacement'] = frame_aggregate_measurements_df['displacement'].interpolate(method='linear', limit_direction='both')\n",
    "            frame_aggregate_measurements_df['cluster_index'] = frame_aggregate_measurements_df['cluster_index'].interpolate(method='linear', limit_direction='both')\n",
    "            frame_aggregate_measurements_df['average_distance_index'] = frame_aggregate_measurements_df['average_distance_index'].interpolate(method='linear', limit_direction='both')\n",
    "            frame_aggregate_measurements_df['unrest_index'] = frame_aggregate_measurements_df['unrest_index'].interpolate(method='linear', limit_direction='both')\n",
    "        else:\n",
    "            pass\n",
    "        measurements_csv_file = os.path.join(output_labels_and_measurements_dir, f\"frame_aggregate_measurements.csv\")\n",
    "        if save_csv_to_drive:\n",
    "            if not os.path.exists(measurements_csv_file):\n",
    "                frame_aggregate_measurements_df.to_csv(measurements_csv_file, index=False, header=False)\n",
    "                print(f\"Saved file {measurements_csv_file}\")\n",
    "            else:\n",
    "                print(f\"File {measurements_csv_file} already exists.\")\n",
    "\n",
    "        frame_aggregate_measurements_list_tot.clear()\n",
    "        del frame_aggregate_measurements_list_tot\n",
    "        del frame_aggregate_measurements_df\n",
    "\n",
    "        batch_aggregate_measurements_df = pd.DataFrame(batch_aggregate_measurements_list)\n",
    "        out_csv_file = os.path.join(output_labels_and_measurements_dir, f\"batch_aggregate_measurements.csv\")\n",
    "        if save_csv_to_drive:\n",
    "            if not os.path.exists(out_csv_file):\n",
    "                batch_aggregate_measurements_df.to_csv(out_csv_file, index=False, header=False)\n",
    "                print(f\"Saved file {out_csv_file}\")\n",
    "            else:\n",
    "                print(f\"File {out_csv_file} already exists.\")\n",
    "        batch_aggregate_measurements_list.clear()\n",
    "        del batch_aggregate_measurements_list\n",
    "        del batch_aggregate_measurements_df\n",
    "        ####################################################\n",
    "    ## end of \"if perform_tracking:\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
