{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88FjEkljpQom"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from scipy.stats import f\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SCARICA IL DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Holstein_diary_cows.csv\"\n",
    "url = \"https://www.dropbox.com/scl/fi/r5sfzpe7oiyup8delhqcw/Holstein_diary_cows.csv?rlkey=tbnxs2z05osci2k6c06wo17av&st=ggok5pnp&dl=0\"\n",
    "# Download the file using wget\n",
    "os.system(f\"wget -O {file_name} '{url}'\")\n",
    "\n",
    "print(f\"File '{file_name}' scaricato nella directory corrente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAbTVLHisUIu"
   },
   "source": [
    "**FUNZIONI PER VALUTARE LE PREDIZIONI SUL TEST SET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TACnVtvIsTFq"
   },
   "outputs": [],
   "source": [
    "def evaluate_predictions(X_test, y_test, y_pred):\n",
    "    # R-squared (R²)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "    # Residual Standard Error (RSE)\n",
    "    # Residuals are the differences between the true values and the predictions\n",
    "    residuals = y_test - y_pred\n",
    "    # For simple linear regression, degrees of freedom = n - 2\n",
    "    rse = np.sqrt(np.sum(residuals**2) / (len(y_test) - 2))\n",
    "\n",
    "    # Output all the results\n",
    "    print(f\"R-squared (R²): {r2:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {mape:.4f}%\")\n",
    "    print(f\"Residual Standard Error (RSE): {rse:.4f}\")\n",
    "    # Create the scatter plot\n",
    "    plt.scatter(X_test, y_test, color='blue', marker='o',\n",
    "                label='ground truth BHB values')\n",
    "    plt.scatter(X_test, y_pred, color='red', marker='+',\n",
    "                label='predicted BHB values')\n",
    "    plt.axhline(y=1.2, color='green', linestyle='--',\n",
    "                linewidth=2, label='Threshold per diagnosi')\n",
    "    # Set labels and title\n",
    "    plt.xlabel('Glu (mmol/L)')\n",
    "    plt.ylabel('BHB (mmol/L)')\n",
    "    plt.title('Scatter plot: ground truth and predictions on test set')\n",
    "\n",
    "    # Add a legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Create a histogram\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size if needed\n",
    "    # kde=True adds a kernel density estimate\n",
    "    sns.histplot(residuals, kde=True, bins=30)\n",
    "    plt.title('Distribuzione dei residui')\n",
    "    plt.xlabel('Residuai')\n",
    "    plt.ylabel('Frequenza')\n",
    "    plt.show()\n",
    "\n",
    "    # Create a Q-Q plot (optional)\n",
    "    sm.qqplot(residuals, line='45', fit=True)\n",
    "    plt.title('Q-Q Plot dei residui')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Function to compute TP, TN, FP, FN\n",
    "def compute_confusion_matrix(boolean_predictions, boolean_ground_truth):\n",
    "    TP = np.sum((boolean_predictions == True) & (\n",
    "        boolean_ground_truth == True))   # Both True\n",
    "    TN = np.sum((boolean_predictions == False) & (\n",
    "        boolean_ground_truth == False))  # Both False\n",
    "    # Predicted True, but False in ground truth\n",
    "    FP = np.sum((boolean_predictions == True) &\n",
    "                (boolean_ground_truth == False))\n",
    "    # Predicted False, but True in ground truth\n",
    "    FN = np.sum((boolean_predictions == False) &\n",
    "                (boolean_ground_truth == True))\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "\n",
    "def compute_classification_metrics(TP, TN, FP, FN):\n",
    "    \"\"\"\n",
    "    Computes accuracy, recall, and F1 score.\n",
    "\n",
    "    Args:\n",
    "      TP: True positives.\n",
    "      TN: True negatives.\n",
    "      FP: False positives.\n",
    "      FN: False negatives.\n",
    "\n",
    "    Returns:\n",
    "      A tuple containing accuracy, recall, and F1 score.\n",
    "    \"\"\"\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    recall = TP / (TP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return accuracy, recall, precision, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJmZBrvZ7oPT"
   },
   "source": [
    "Cliccare sull'icona della cartella qui a sinistra. Quando si apre lo spazio di lavoro dei file, trascinare il file 'Holstein_diary_cows.csv' dal proprio computer all'area qui a sinistra. In seguito eseguire la prossima cella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkwHYTIM7lvt"
   },
   "outputs": [],
   "source": [
    "cvs_source= 'Holstein_diary_cows.csv'\n",
    "df = pd.read_csv(cvs_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "pluh8GXIpNBh"
   },
   "outputs": [],
   "source": [
    "# @title Eseguire questa cella per creare il dataset solo se non si è riusciti a caricare il file csv dal proprio computer\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate X values in the range 1.8–4.5\n",
    "X_0 = np.random.uniform(1.8, 4.5, 30)\n",
    "mu = (2.29 + 2.462) / 2\n",
    "sigma = 0.1\n",
    "X_1 = np.random.normal(loc=mu, scale=sigma, size=30)\n",
    "mu = (1.8 + 4.5) / 2\n",
    "sigma = 1.5\n",
    "X_2 = np.random.normal(loc=mu, scale=sigma, size=110)\n",
    "mu = (2.29 + 2.462) / 2\n",
    "sigma = 1.0\n",
    "X_3 = np.random.normal(loc=mu, scale=sigma, size=60)\n",
    "X = np.concatenate((X_0, X_1, X_2, X_3))\n",
    "X = X[X < 4.5]\n",
    "X = X[X > 1.8]\n",
    "# Sort the X values in ascending order\n",
    "X.sort()\n",
    "# Define the parameters for the linear relation Y = aX + B\n",
    "a = 0.220\n",
    "b = -1.98\n",
    "c = 4.655\n",
    "\n",
    "Y = a*(X**2) + b*X + c\n",
    "\n",
    "# Calculate Y values\n",
    "Y_noisy = np.zeros_like(Y)\n",
    "\n",
    "# Add Gaussian noise while ensuring non-negativity\n",
    "for i in range(len(Y)):\n",
    "    noise = np.random.normal(0, 0.1)\n",
    "    v = Y[i] + noise\n",
    "    if v <= 0:\n",
    "        Y_noisy[i] = Y[i] + np.random.normal(0, 0.000001)\n",
    "    else:\n",
    "        Y_noisy[i] = v\n",
    "\n",
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame({'Glu': X, 'BHB': Y_noisy})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aY-0I3Bk8aiH"
   },
   "source": [
    "**Eseguire la prossima cella per visualizzare il dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4S5fD9AeqcMi"
   },
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.scatter(df['Glu'], df['BHB'])\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Glu (mmol/L)')\n",
    "plt.ylabel('BHB (mmol/L)')\n",
    "plt.title('Scatter plot: Glu vs BHB')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05sLXt4K8hTU"
   },
   "source": [
    "**DIVIDI IL DATASET IN 80% TRAIN E 20% TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXmhvst18zn9"
   },
   "outputs": [],
   "source": [
    "X = df[['Glu']]  # Features (independent variable)\n",
    "y = df['BHB']    # Target (dependent variable)\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvmAUF05FI7G"
   },
   "source": [
    "**CREA ED ALLENA UN MODELLO DI REGRESSIONE LINEARE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uW0uA2OcpO7j"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "\n",
    "print(f\"Slope: {slope}\")\n",
    "print(f\"Intercept: {intercept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAtzfsbK2Ye_"
   },
   "source": [
    "**VISUALIZZA LA RETTA DI REGRESSIONE ED APPLICA LA F-STATISTIC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyYn7OT9tje5"
   },
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.scatter(df['Glu'], df['BHB'])\n",
    "# Generate x-values for the regression line\n",
    "x_line = np.array([df['Glu'].min(), df['Glu'].max()])\n",
    "\n",
    "# Calculate y-values for the regression line using slope and intercept\n",
    "y_line = slope * x_line + intercept\n",
    "# Plot the regression line\n",
    "plt.plot(x_line, y_line, color='red', label='Retta di regressione')\n",
    "# Set labels and title\n",
    "plt.xlabel('Glu (mmol/L)')\n",
    "plt.ylabel('BHB (mmol/L)')\n",
    "plt.title('Scatter plot: Glu vs BHB')\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# F-statistic (based on the regression model)\n",
    "# We will use statsmodels to compute the F-statistic for the regression model\n",
    "# Add constant (intercept) to X_test\n",
    "X_test_with_const = sm.add_constant(X_test)\n",
    "# Fit the model using statsmodels\n",
    "model_sm = sm.OLS(y_test, X_test_with_const).fit()\n",
    "f_statistic = model_sm.fvalue  # Extract F-statistic\n",
    "print(f\"F-statistic: {f_statistic:.4f}\")\n",
    "\n",
    "df1 = 1  # Numerator degrees of freedom\n",
    "df2 = 172  # Denominator degrees of freedom\n",
    "\n",
    "# Compute the p-value\n",
    "p_value = f.sf(f_statistic, df1, df2)  # Survival function: P(F >= F_stat)\n",
    "print(f\"P-value: {p_value:.20f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kl42UQXq2Ye_"
   },
   "source": [
    "**APPLICA IL MODELLO SUL TEST SET E VALUTA LE SUE PREDIZIONI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LfoX7FYCqMvb"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "evaluate_predictions(X_test, y_test, y_pred)\n",
    "\n",
    "if not isinstance(y_test, np.ndarray):\n",
    "  y_test = y_test.values\n",
    "\n",
    "threshold = 1.2  # The threshold value\n",
    "\n",
    "# Create boolean arrays\n",
    "bool_y_test = y_test >= threshold\n",
    "bool_y_pred = y_pred >= threshold\n",
    "\n",
    "# Compute metrics for each prediction array\n",
    "TP, TN, FP, FN = compute_confusion_matrix(bool_y_pred, bool_y_test)\n",
    "accuracy, recall, precision, f1_score = compute_classification_metrics(\n",
    "    TP, TN, FP, FN)\n",
    "\n",
    "print(\"Matrice di confusione:\")\n",
    "print(f\"TP: {TP}\")\n",
    "print(f\"TN: {TN}\")\n",
    "print(f\"FP: {FP}\")\n",
    "print(f\"FN: {FN}\")\n",
    "print(\"Metriche del classificatore:\")\n",
    "print(f\"Accuratezza: {accuracy}\")\n",
    "print(f\"Richiamo: {recall}\")\n",
    "print(f\"Precisione: {precision}\")\n",
    "print(f\"F1: {f1_score}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
